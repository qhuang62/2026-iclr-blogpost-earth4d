<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Diffusion as Infinite Hierarchical VAEs - Do Diffusion Models Generalize Better than Deep VAEs? | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="This blogpost unifies Diffusion Models and Variational Autoencoders. We demonstrate that DPMs are mathematically equivalent to Hierarchical VAEs (HVAEs) in the limit of infinite depth. By analyzing this architectural link, we explain why diffusion models avoid the posterior collapse that plagues deep VAEs and identify the sweet spot for generalization where these models perform best."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026-iclr-blogpost-earth4d/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026-iclr-blogpost-earth4d/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026-iclr-blogpost-earth4d/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026-iclr-blogpost-earth4d/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026-iclr-blogpost-earth4d/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026-iclr-blogpost-earth4d/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://qhuang62.github.io/2026-iclr-blogpost-earth4d/blog/2026/generalization-in-diffusion-as-infinite-hvae/"> <script src="/2026-iclr-blogpost-earth4d/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026-iclr-blogpost-earth4d/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026-iclr-blogpost-earth4d/assets/js/distillpub/template.v2.js"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}.box-note{font-size:18px;padding:15px 15px 10px 10px;margin:2px 2px 2px 5px;border-left:7px solid #ab4a09;border-radius:1px}d-article .box-note{background-color:rgba(100,4,255,0.03);border-left-color:#7614ff}.caption{color:gray;font-style:italic}.slider-example-focus{transition:box-shadow 200ms ease-in-out}.slider-example-focus:focus{outline:0;box-shadow:0 0 15px 5px #0c5d10}details summary{cursor:pointer;color:#7614ff;font-weight:bold;padding:4px 8px;border-radius:4px;transition:background-color .3s,color .3s}details[open] summary{background-color:#e6f0ff}details summary:hover{color:#7614ff;background-color:#cce0ff}# a[href^="#"]{# color:#f70!important;# font-style:italic;# text-decoration:none!important;#}# a[href^="#"]:hover{# text-decoration:underline!important;#}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Diffusion as Infinite Hierarchical VAEs - Do Diffusion Models Generalize Better than Deep VAEs?",
            "description": "This blogpost unifies Diffusion Models and Variational Autoencoders. We demonstrate that DPMs are mathematically equivalent to Hierarchical VAEs (HVAEs) in the limit of infinite depth. By analyzing this architectural link, we explain why diffusion models avoid the posterior collapse that plagues deep VAEs and identify the sweet spot for generalization where these models perform best.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026-iclr-blogpost-earth4d/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026-iclr-blogpost-earth4d/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026-iclr-blogpost-earth4d/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026-iclr-blogpost-earth4d/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026-iclr-blogpost-earth4d/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026-iclr-blogpost-earth4d/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/" rel="external nofollow noopener" target="_blank"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/" rel="external nofollow noopener" target="_blank">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/" rel="external nofollow noopener" target="_blank">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/" rel="external nofollow noopener" target="_blank">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Diffusion as Infinite Hierarchical VAEs - Do Diffusion Models Generalize Better than Deep VAEs?</h1> <p>This blogpost unifies Diffusion Models and Variational Autoencoders. We demonstrate that DPMs are mathematically equivalent to Hierarchical VAEs (HVAEs) in the limit of infinite depth. By analyzing this architectural link, we explain why diffusion models avoid the posterior collapse that plagues deep VAEs and identify the sweet spot for generalization where these models perform best.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#1-background">1. Background</a> </div> <div> <a href="#2-hierarchical-variational-auto-encoders">2. Hierarchical Variational Auto-Encoders</a> </div> <div> <a href="#3-denoising-diffusion-probabilistic-models-ddpms">3. Denoising Diffusion Probabilistic Models (DDPMs)</a> </div> <div> <a href="#4-continuous-time-limit">4. Continuous-time limit</a> </div> <div> <a href="#5-concluding-remarks">5. Concluding Remarks</a> </div> </nav> </d-contents> <h2 id="1-motivations">1. Motivations</h2> <p>Diffusion Probabilistic Models (DPMs) have largely eclipsed Variational Auto-Encoders (VAEs) as the gold standard for high-fidelity generative modeling. Yet, treating them as rival paradigms obscures a deeper theoretical continuity. In this post, we explain that DPMs are not a departure from VAEs, but rather their ultimate expression: they are rigorously equivalent to properly parameterized Hierarchical VAEs (HVAEs) in the limit of infinite depth with a fixed, noise-injecting inference process. We evaluate these models on three benchmark datasets—CIFAR-10, CelebA, and ImageNet—as well as the CERA weather dataset <d-cite key="CERRA"></d-cite>, to illustrate both image and spatio-temporal generalization. By bridging the discrete layers of deep VAEs with the continuous trajectories of Stochastic Differential Equations, we show that this architectural limit is more than a mathematical artifact. It appears as the structural key that allows diffusion models to circumvent posterior collapse, enabling them to generalize far beyond the reach of finite hierarchical models.</p> <p>To provide an intuitive sense of these differences in reconstruction quality, we compare the output of HVAEs and DDPMs against the ground truth using interactive sliders. These sliders allow readers to visually assess how model depth or diffusion steps affect fidelity in both natural and structured data domains:</p> <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"> <style>.slider-row{display:flex;gap:10px;justify-content:center;align-items:flex-start;margin:10px 0}.slider-box{width:23%;max-width:280px;position:relative}img-comparison-slider{height:180px;--divider-width:6px;--divider-color:#fff;--default-handle-color:#fff;outline:0;box-shadow:none;filter:drop-shadow(0 0 10px white) drop-shadow(0 0 .5px white)}img-comparison-slider::part(divider){box-shadow:0 10px 0 10px white;border-radius:100px}img-comparison-slider:focus,img-comparison-slider *:focus{outline:none!important;box-shadow:none!important}.caption-small{text-align:center;font-size:.75em;color:gray;font-style:italic;margin-top:3px}.slider-label{position:absolute;top:-30px;left:0;width:50%;text-align:center;font-size:.7em;font-weight:bold;color:#404040;pointer-events:none}.slider-label.right{left:50%}</style> <p><br></p> <div class="slider-row"> <div class="slider-box"> <div class="slider-label">HVAE (k=8)</div> <div class="slider-label right">GT</div> <img-comparison-slider> <img slot="first" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_2.png"> <img slot="second" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_GT_1.png"> </img-comparison-slider> <div class="caption-small"> HVAE (k=8) vs Ground-truth (GT)</div> </div> <div class="slider-box"> <div class="slider-label">HVAE (k=32)</div> <div class="slider-label right">GT</div> <img-comparison-slider> <img slot="first" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_2.png"> <img slot="second" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_GT_1.png"> </img-comparison-slider> <div class="caption-small"> HVAE (k=32) vs Ground-truth (GT)</div> </div> <div class="slider-box"> <div class="slider-label">DDPM (T=100)</div> <div class="slider-label right">GT</div> <img-comparison-slider> <img slot="first" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_4.png"> <img slot="second" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_GT_1.png"> </img-comparison-slider> <div class="caption-small">DDPM (T=100) vs Ground-truth (GT)</div> </div> <div class="slider-box"> <div class="slider-label">DDPM (T=1000)</div> <div class="slider-label right">GT</div> <img-comparison-slider> <img slot="first" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_5.png"> <img slot="second" width="100%" src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/slider_GT_1.png"> </img-comparison-slider> <div class="caption-small"> DDPM (T=1000) vs Ground-truth (GT)</div> </div> </div> <h2 id="2-hierarchical-variational-auto-encoders">2. Hierarchical Variational Auto-Encoders</h2> <h3 id="21-variational-auto-encoders-vaes">2.1 Variational Auto-Encoders (VAEs)</h3> <p>Since their introduction in 2014 by <d-cite key="kingma2013auto, rezende2014stochastic"></d-cite>, Variational Auto-Encoders (VAE) have revolutionized the field of Variational Inference (VI) and have had a broad impact in many areas of machine learning. A VAE operates in a <em>latent variable model</em>, defined by a joint density $p_{\theta}(x, z) = p_{\theta}(x \mid z)p(z)$. Here, $z$ denotes the latent variables with a prior density $p(z)$, and $p_{\theta}(x \mid z)$ is the observation model (or likelihood).</p> <p>A key challenge in Bayesian inference is to learn the posterior $p_{\theta}(z \mid x)=p_{\theta}(x, z)/p_{\theta}(x)$. This density is often intractable due to the normalizing constant $p_{\theta}(x)$. VI introduces a parametric family of distributions ${q_{\phi}(z \mid x):\phi\in\Phi}$, referred to as the inference model or approximate posterior, and tries to find the parameter $\phi$ that yields the best approximation of the true posterior $p_{\theta}(z \mid x)$. The quality of the approximation is quantified by a divergence measure, often the reverse Kullback-Leibler (KL) divergence. Minimizing the reverse KL divergence between the approximate posterior and the true posterior is equivalent to maximizing the Evidence Lower Bound (ELBO), $-\mathcal{L}(\theta, \phi; x)$, which also serves as a tractable lower bound to the marginal likelihood:</p> \[\begin{equation} \label{eq:elbo} \log p_{\theta}(x) \geq -\mathcal{L}(\theta, \phi; x) = \mathbb{E}_{q_{\phi}(z \mid x)}[\log p_{\theta}(x \mid z)] - D_{\mathrm{KL}}(q_{\phi}(z \mid x) \,\|\, p(z)). \end{equation}\] <p>VAEs crucially learn both the inference model $q_{\phi}(z \mid x)$ and the generative model $p_{\theta}(x \mid z)$ at the same time. This makes them particularly versatile on a variety of tasks, e.g., finding a meaningful latent representation of the data, approximating a complex posterior distribution, or learning a generative model. In this blogpost, we are interested in the latter (see <a href="#fig-overview">Figure 1</a> for an overview).</p> <figure id="fig:overview" class="caption"> <img src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/diffusion_vs_hvae_v2.png" alt="Overview of Diffusion and HVAE" style="max-width:100%;height:auto;"> <div class="caption"> <strong>Figure 1:</strong> An overview of HVAE and Diffusion. While HVAEs (left) rely on a finite depth of hierarchical latents for generation, Diffusion models (right) unfold this process over time, effectively operating as an HVAE with infinitely many layers sharing the same parameters. </div> </figure> <p>While this is an elegant formulation, a single layer of Gaussian latents is often insufficient to capture the complex nature of high-dimensional data like natural images.</p> <h3 id="22-hierarchical-variational-auto-encoders">2.2 Hierarchical Variational Auto-Encoders.</h3> <p>To enhance the expressivity of both the generative model and the inference model, a natural extension of the VAE framework is to consider a hierarchy of latent variables $z = {z_1, \dots, z_T}$. Following the formulation of Hierarchical VAEs (HVAEs) <d-cite key="sonderby2016ladder, vahdat2020nvae"></d-cite>, the joint distribution factorizes in a top-down fashion. We define $z_T$ as the highest-level latent variable and $z_0 = x$ as the observed data:</p> \[\begin{equation} p_{\theta}(z_0, z_{1:T}) = p(z_T) \prod_{t=1}^{T} p_{\theta}(z_{t-1} \mid z_t). \end{equation}\] <p>In this formulation, the generative process creates a cascade of conditional dependencies from the latent $z_T$ down to the data $z_0$.</p> <p>Consistent with this structure, we define the inference model as a bottom-up factorization, conditioning each latent layer on the previous one:</p> \[\begin{equation} q_{\phi}(z_{1:T} \mid z_0) = q_{\phi}(z_1 \mid z_0) \prod_{t=2}^{T} q_{\phi}(z_t \mid z_{t-1}). \end{equation}\] <p><strong>The Hierarchical ELBO.</strong> By substituting these factorized forms into the general ELBO definition,</p> \[\mathcal{L}(\theta, \phi; z_0) = \mathbb{E}_{q_{\phi}(z_{1:T} \mid z_0)} \left[ \log p_{\theta}(z_0, z_{1:T}) - \log q_{\phi}(z_{1:T} \mid z_0) \right],\] <p>we can derive a layer-wise objective. Grouping the terms by time step $t$ reveals the following structure:</p> \[\begin{align}\label{eq:elbo-hvae} \mathcal{L}_{\mathrm{HVAE}}(\theta, \phi, z_0) &amp;= \mathbb{E}_{q_{\phi}} [\log p_{\theta}(z_0 \mid z_1)] \\ &amp; - \sum_{t=2}^T \mathbb{E}_{q_{\phi}} [D_{\mathrm{KL}}(q_{\phi}(z_t \mid z_{t-1}) \mid p_{\theta}(z_{t-1} \mid z_t))] \nonumber \\ &amp; - D_{\mathrm{KL}}(q_{\phi}(z_T \mid z_0) \mid p(z_T)). \nonumber \end{align}\] <aside class="l-body box-note"> <p>This decomposition reveals three distinct structural components of the loss function:</p> <ul> <li> <p><strong>1. Reconstruction:</strong> The first term of Eq. \eqref{eq:elbo-hvae} measures how well the model can reconstruct the original data from the latent variable $z_1$, encouraging accurate generation.</p> </li> <li> <p><strong>2. Consistency Terms:</strong> $\sum D_{\mathrm{KL}}(q_{\phi}(z_t \mid z_{t-1}) \,|\, p_{\theta}(z_{t-1} \mid z_t))$ — encourages the generative transitions $p_{\theta}(z_{t-1} \mid z_t)$ to match the inference transitions $q_{\phi}(z_t \mid z_{t-1})$, ensuring smooth flow along the latent trajectory.</p> </li> <li> <p><strong>3. Prior Matching:</strong> $D_{\mathrm{KL}}(q_{\phi}(z_T \mid z_0) \,|\, p(z_T))$ — aligns the final latent distribution with the prior, similar to the standard VAE, to regularize the latent space.</p> </li> </ul> </aside> <p><br></p> <p><strong>Optimization Challenges.</strong> Despite the theoretical advantages of hierarchical latent spaces, training deep HVAEs (where $T \gg 1$) presents significant difficulties. <d-cite key="vahdat2020nvae"></d-cite> and <d-cite key="huang2021variational"></d-cite> highlight several critical issues:</p> <ul> <li> <p><em>Posterior Collapse (Generalization issue).</em> This is the most pervasive failure mode in autoregressive and hierarchical models. The generative model effectively decouples from the deep latent variables, causing the approximate posterior $q_{\phi}(z_t \mid z_{t-1})$ to collapse to the prior $p_{\theta}(z_t \mid z_{t-1})$. This can reduce the effective depth of the model.</p> </li> <li> <p><em>Training Instability.</em> Maximizing the ELBO involves balancing the reconstruction term against a sum of KL divergence terms. As the hierarchy deepens, this optimization becomes unstable due to the difficulty of aligning the encoder and decoder distributions across multiple stochastic layers. Achieving stable convergence often requires specific architectural interventions, such as spectral regularization or residual parameterizations <d-cite key="vahdat2020nvae"></d-cite>.</p> </li> <li> <p><em>Reconstruction Quality.</em> VAEs are known to produce blurry samples when modeling high-dimensional data like images. This is largely attributed to the definition of the observation model $p_{\theta}(z_0 \mid z_1)$ (typically a factorized Gaussian), where the maximization of the log-likelihood is equivalent to minimizing a squared $L^2$ norm. This metric is insensitive to high-frequency spatial structures.</p> </li> </ul> <p>On the task of generative modeling, Diffusion Models <d-cite key="sohl2015deep"></d-cite>, <d-cite key="ho2020denoising"></d-cite>, and <d-cite key="song2020score"></d-cite> have emerged as the prime framework to perform high-fidelity generation, achieving both quality and variety of the samples.</p> <h2 id="3-denoising-diffusion-probabilistic-models-ddpms">3. Denoising Diffusion Probabilistic Models (DDPMs)</h2> <p>The core idea behind diffusion models is to define a fixed process that destroys data, and to learn the reversal of this process. We adopt the formalism from <d-cite key="ho2020denoising"></d-cite>.</p> <p><strong>The Forward Process.</strong> In contrast to VAEs, which learn the approximate posterior parameters, Denoising Diffusion Probabilistic Models (DDPMs) <d-cite key="ho2020denoising"></d-cite> define a <em>fixed</em> inference process. This forward process is a Markov chain $q(z_{1:T} \mid z_0)$ that gradually adds Gaussian noise to the data $z_0$ according to a pre-defined variance schedule $\beta_1, \dots, \beta_T$: \(\begin{equation} q(z_t \mid z_{t-1}) = \mathcal{N}(z_t; \sqrt{1-\beta_t} z_{t-1}, \beta_t \mathbf{I}). \end{equation}\)</p> <p>A critical advantage of using Gaussian transitions is that the composition of linear Gaussian kernels remains Gaussian. This allows us to marginalize out the intermediate steps $z_{1:t-1}$ and derive a closed-form distribution for $z_t$ conditioned directly on the input $z_0$. By defining $\bar{\alpha}<em>t = \prod</em>{s=1}^t (1-\beta_{s})$, we get \(\begin{equation} q(z_t \mid z_0) = \mathcal{N}(z_t; \sqrt{\bar{\alpha}_t} z_0, (1-\bar{\alpha}_t) \mathbf{I}). \end{equation}\)</p> <p>This property renders the sampling of $z_t$ computationally tractable at any arbitrary timestep $t$ without the need to iteratively simulate the chain. It will be instrumental in optimizing the training objective.</p> <p><strong>The Reverse Process and Parameterization.</strong></p> <p>The generative model is defined as a reverse Markov chain $p_{\theta}(x_{0:T})$ which learns to revert the diffusion process. Starting from a standard Gaussian prior $p(x_T) = \mathcal{N}(x_T; 0, \mathbf{I})$, the transitions are modeled as Gaussian distributions:</p> \[\begin{equation} p_{\theta}(z_{t-1} \mid z_t) = \mathcal{N}(z_{t-1}; \mu_{\theta}(z_t, t), \Sigma_{\theta}(z_t, t)). \end{equation}\] <p>While the variances $\Sigma_{\theta}$ are often fixed according to a predefined schedule, the means $\mu_{\theta}$ must be learned.</p> <details> <summary>Click here for details about DDPM derivation complement</summary> <div markdowk="1"> To derive an efficient parameterization for $\mu_{\theta}$, we observe that the true posterior of the forward process, conditioned on $x_0$, is a tractable Gaussian: $$ \begin{equation} q(x_{t-1} \mid x_t, x_0) = \mathcal{N}(x_{t-1}; \tilde{\mu}_t(x_t, x_0), \tilde{\beta}_t \mathbf{I}). \end{equation} $$ Crucially, the mean of this true posterior can be expressed as $$\tilde{\mu}_t(x_t, x_0) = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \varepsilon \right),$$ where we reparameterize $x_t=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\varepsilon$, with $\varepsilon\sim\mathcal{N}(0, \mathbf{I})$. Motivated by this functional form, <d-cite key="ho2020denoising"></d-cite> propose parameterizing the model mean $\mu_{\theta}$ by estimating the noise component directly via a neural network $\varepsilon_{\theta}(x_t, t)$ (typically a U-Net <d-cite key="ronneberger2015u"></d-cite>). </div> </details> <p><br></p> <p><strong>The Variational Lower Bound.</strong> The reverse process is typically learned by optimizing the ELBO. By expanding the joint factorization, the objective writes:</p> \[\begin{equation*} \mathcal{L}_{\mathrm{DDPM}}(\theta) = -\mathbb{E}_q\!\left[\log\frac{p_{\theta}(z_{0:T})}{q(z_{1:T} \mid z_0)}\right] = \mathbb{E}_{q}\!\left[ -\log p(z_T) - \sum_{t=1}^T \log \frac{p_{\theta}(z_{t-1} \mid z_t)}{q(z_t \mid z_{t-1})} \right]. \end{equation*}\] <p>Here, the expectations are taken with respect to $q(z_{1:T} \mid z_0)$. A key insight in diffusion models is that the forward process posterior $q(z_{t-1} \mid z_t, z_0)$ is tractable when conditioned on $z_0$. Using Bayes’ rule, we can rewrite the forward transition as $q(z_t \mid z_{t-1}) = \frac{q(z_t \mid z_{t-1}, z_0) q(z_{t-1} \mid z_0)}{q(z_t \mid z_0)}$. Substituting this into the objective allows us to decompose the loss into three interpretable terms:</p> \[\begin{align}\label{eq:elbo-dpm} \mathcal{L}_{\mathrm{DPM}}(\theta) &amp;= \underbrace{D_{\mathrm{KL}}(q(z_T \mid z_0) \,||\, p(z_T))}_{L_T} \\ &amp; + \sum_{t=2}^T \underbrace{D_{\mathrm{KL}}(q(z_{t-1} \mid z_t, z_0) \,||\, p_{\theta}(z_{t-1} \mid z_t))}_{L_{t-1}} \\ \nonumber &amp; - \underbrace{\log p_{\theta}(z_0 \mid z_1)}_{L_0}. \nonumber \end{align}\] <p>This decomposition highlights an exact structural parallel with the HVAE objective Eq. \eqref{eq:elbo-hvae}:</p> <ul> <li> <p><strong>$L_T$ (Prior Matching):</strong> Analogous to the top-level KL in HVAEs. In the DPM framework, this term contains no learnable parameters and is effectively constant during training.</p> </li> <li> <p><strong>$L_{t-1}$ (Consistency):</strong> These terms are the core optimization objective. They force the learned reverse transition $p_\theta(z_{t-1} \mid z_t)$ (the generative step) to match the tractable posterior $q(z_{t-1} \mid z_t, z_0)$.</p> </li> <li> <p><strong>$L_0$ (Reconstruction):</strong> This term represents the likelihood of the data given the first latent variable, directly mirroring the reconstruction loss in standard VAEs.</p> </li> </ul> <p>This is the first layer of understanding diffusion models as HVAEs. We will see in the next section that diffusion models can be interpreted as infinitely deep HVAEs where the encoder is fixed.</p> <h2 id="4-continuous-time-limit">4. Continuous-time limit</h2> <h3 id="41-the-score-matching-view-of-diffusion">4.1 The score-matching view of diffusion</h3> <p><strong>Simplification to Denoising Score Matching.</strong> Although Eq. \eqref{eq:elbo-dpm} provides the bound, optimizing it directly is often suboptimal for sample quality. By substituting the parameterization of $\mu_{\theta}$ from Eq. \eqref{eq:mu_theta}, the consistency term reduces to</p> \[\begin{equation} L_{t-1} \propto \mathbb{E}_{z_0, \varepsilon} \left[ \lambda_t \| \varepsilon - \varepsilon_{\theta}(z_t, t) \|^2 \right], \end{equation}\] <p>where $\propto$ denotes equality up to an additive constant, and $\lambda_t$ is a complicated weighting function derived from the variance schedule. <d-cite key="ho2020denoising"></d-cite> empirically demonstrates that discarding this weighting term (i.e., setting $\lambda_t = 1$) improves sample generation. This leads to the simplified objective used in practice:</p> \[\begin{equation} \label{eq:loss-simple} \mathcal{L}_{\mathrm{simple}}(\theta) = \mathbb{E}_{t, z_0, \varepsilon} \left[ \| \varepsilon - \varepsilon_{\theta}(\sqrt{\bar{\alpha}_t}z_0 + \sqrt{1 - \bar{\alpha}_t}\varepsilon, t) \|^2 \right]. \end{equation}\] <p>This simplified objective is equivalent to denoising score matching over multiple noise scales <d-cite key="vincent2011connection, song2020score"></d-cite>. Indeed, the true score of the conditional distribution</p> \[q(z_t \mid z_0) = \mathcal{N}(z_t; \sqrt{\bar{\alpha}_t} z_0, (1-\bar{\alpha}_t) \mathbf{I}),\] <p>is analytically tractable: $\nabla_{z_t} \log q(z_t \mid z_0) = -\frac{z_t - \sqrt{\bar{\alpha}_t}z_0}{1-\bar{\alpha}_t} = -\frac{\varepsilon}{\sqrt{1-\bar{\alpha}_t}}$. This means we can train a model to effectively learn this score function.</p> <p><strong>Continuous-Time Formulation: The SDE Perspective.</strong> The connection between diffusion models and score matching becomes explicit when we consider the limit of infinite timesteps, $T \to +\infty$. In this regime, the discrete transitions converge to a continuous-time Stochastic Differential Equation (SDE). <d-cite key="song2020score"></d-cite> formalize the forward process as an Itô SDE:</p> \[\begin{equation}\label{eq:forward-sde} \mathrm{d} z= f(z,t)\mathrm{d} t + g(t)\mathrm{d} w. \end{equation}\] <p>where $f(z, t)$ is the drift coefficient, $g(t)$ is the diffusion coefficient, and $w$ represents a standard Wiener process. As time $t$ flows from $0$ to $T$, this SDE transforms the data distribution $p_0$ into the prior distribution $p_T$.</p> <p>A result by <d-cite key="anderson1982reverse"></d-cite> guarantees that for any forward SDE, there exists a corresponding reverse-time SDE given by:</p> \[\begin{equation} \label{eq:reverse-sde} \mathrm{d} z = \left[f(z, t) - g(t)^2 \nabla_z \log q_t(z)\right] \mathrm{d} t + g(t) \mathrm{d} \bar w, \end{equation}\] <p>where $d\bar w$ is a standard Wiener process when time flows backwards from $T$ to $0$, and $\nabla_z\log q_t(z)$ denotes the score function of the forward marginal density at time $t$.</p> <p>To generate data, we must simulate Eq. \eqref{eq:reverse-sde}. Since the drift and diffusion coefficients are chosen by design, the only unknown quantity is the score function. Therefore, the learning objective is to train a time-dependent neural network $s_{\theta}(z, t)$ to approximate the true score:</p> \[\begin{equation} s_{\theta}(z, t) \approx \nabla_z \log q_t(z). \end{equation}\] <p>Optimization is performed via score matching, in the sens of Fisher divergence minimization. This recovers the DDPM noise prediction objective as explained above.</p> <h3 id="42-infinite-depth-limit-of-hvaes">4.2 Infinite depth limit of HVAEs</h3> <p>Tzen et al. (2019) <d-cite key="tzen2019neural"></d-cite> proves that, under the right conditions, the characterization of diffusion models as infinite-depth HVAEs can be formalized in a rigorous way.</p> <p>We already saw that HVAEs define a hierarchy of latent variables $z = {z_1, \dots, z_T}$. Let us associate the layer index $k$ with a time $t_k = k/T \in [0,1]$ and define the step size $\Delta t = 1/T$. When layers are built as residual blocks (see <a href="#fig-overview">Figure 1</a>), each new layer of the HVAE does the following operation, which can be viewed as an Euler-Maruyama discretization:</p> \[\begin{equation} z_{t_{k-1}} = z_{t_k} + f_{\theta}(z_{t_k}, t_k)\Delta t + g_{\theta}(z_{t_k}, t_k) \sqrt{\Delta t} \, \varepsilon_k, \end{equation}\] <p>where $\varepsilon_k \sim \mathcal{N}(0, \mathbf{I})$ are standard Gaussian vectors, and $f_{\theta}(z_{t_k}, t_k)$ (resp. $g_{\theta}(z_{t_k}, t_k)$) is the mean (resp. standard deviation) of the decoder $p_{\theta}(z_{t-1} \mid z_t)$.</p> <p><strong>Latent prior.</strong> As $T \to \infty$ and $\Delta t \to 0$, the most critical aspect becomes the transformation of the latent prior. In an HVAE, the randomness comes from the <em>independent</em> noise vectors ${\varepsilon_1, \dots, \varepsilon_T}$. Invoking Donsker’s Theorem, <d-cite key="tzen2019neural"></d-cite> identify that the partial sums of these scaled noise vectors converge to a Wiener process.</p> <p>Consequently, the latent space changes from a high-dimensional Euclidean space $\mathbb{R}^{d\times T}$ to the Wiener space of continuous paths equipped with the Wiener measure.</p> <p>The generative model then becomes the solution to the Itô SDE driven by this Wiener process:</p> \[\begin{equation}\label{eq:hvae-sde} \mathrm{d} z_t = f_{\theta}(z_t, t)\mathrm{d} t + g_{\theta}(z_t, t)\mathrm{d} \bar{w}_t. \end{equation}\] <figure id="fig:layer-variance" class="caption"> <div class="l-page"> <iframe src="/2026-iclr-blogpost-earth4d/assets/html/2026-04-27-generalization-in-diffusion-as-infinite-hvae/layer_time_correspondence_interactive.html" frameborder="0" scrolling="no" height="400px" width="100%"></iframe> </div> <div class="caption"> <strong>Figure 2:</strong> Comparison of hierarchical variance profiles between HVAE and DDPM across three datasets (CIFAR-10, CelebA, ImageNet-32). HVAE exhibits discrete, step-like increases in perceptual sample variance across layers, while DDPM shows a smooth, continuous increase over diffusion time. The shaded region highlights the approximate transition zone where both models reach intermediate variance levels. </div> </figure> <p><a href="#fig:layer-variance">Figure 2</a>, illustrates the structural parallel between the discrete latent hierarchy of HVAEs and the continuous time horizon of DPMs. To quantify the semantic contribution of each stage, we utilize the Learned Perceptual Image Patch Similarity (LPIPS) metric <d-cite key="zhang2018unreasonable"></d-cite>, as pixel-wise MSE is insufficient for capturing high-level semantic emergence.</p> <p>The plot reveals three key behaviors:</p> <ul> <li> <p><strong>Continuous vs. Discrete Dynamics:</strong> The DDPM trajectory (solid blue line) acts as the continuous limit of the HVAE’s discrete layering (dashed orange steps).</p> </li> <li> <p><strong>The Semantic Phase Transition:</strong> Both models exhibit a sigmoidal rise in perceptual variance within the normalized depth window $x \in [0.35, 0.55]$. This region marks the transition where the generative process shifts from resolving low-frequency global structure (abstract priors) to high-frequency textural details.</p> </li> <li> <p><strong>Feature Saturation:</strong> The plateau near $x \to 1$ suggests that the deepest layers (or earliest diffusion times) contribute minimally to perceptual changes, aligning with the “dead layer” phenomenon observed in deep generative stacks <d-cite key="kingma2021variational"></d-cite>.</p> </li> </ul> <p><strong>Mapping to Diffusion Models.</strong> In an HVAE, $f_{\theta}$ is a single neural network learning the full drift of the generative trajectory. In diffusion models, however, the reverse drift has a precise structure, as seen in Eq. \eqref{eq:reverse-sde}. We can identify the HVAE decoder $f_{\theta}$ to the composite drift term in Eq. \eqref{eq:reverse-sde}, where the true score is replaced by $s_{\theta}(z, t)$:</p> \[\begin{equation} f_{\theta}(z, t) \leftrightarrow f(z, t) - g(t)^2 s_{\theta}(z, t). \end{equation}\] <p>It is also important to note that the general infinite-depth HVAE learns both the drift $f_{\theta}$ and the diffusion coefficient $g_{\theta}$. On the other hand, DPMs fix the diffusion coefficient to a scalar schedule $g_{\theta}(z, t) \equiv g(t)$.</p> <h3 id="43-continuous-time-elbo">4.3 Continuous-time ELBO</h3> <p>We have established that structurally, infinitely deep HVAEs are equivalent to diffusion models when parameterized correctly. However, this does not provide insight into the optimization procedure itself. How do we define the ELBO for a model with infinite layers?</p> <p>A bottom-up derivation that bridges the discrete HVAE loss and the continuous diffusion objective is provided by <d-cite key="kingma2021variational"></d-cite>. By viewing the layer index $t$ as a continuous variable, the ELBO simplifies into an integral over the Signal-to-Noise Ratio (SNR).</p> <p><strong>Derivation Sketch.</strong> Before we provide a sketch of the continuous-time ELBO derivation, it is important to note that parameterizing the model to predict the clean data $\hat{z}_\theta$</p> <p>is equivalent to predicting the nois $\varepsilon_\theta$ (or the score $s_{\theta}$).</p> <p>Indeed, these quantities are simply related by affine transformations. The $\hat{z}_\theta$ parameterization is more convenient for the analysis presented below.</p> <p>We begin with the discrete diffusion loss term from Eq. \eqref{eq:elbo-hvae}:</p> \[\mathcal{L}_T = \sum_{t=1}^T \mathbb{E}_{q}[D_{\mathrm{KL}}(q(z_{s} \mid z_t, z_0) \mid p_{\theta}(z_{s} \mid z_t))],\] <p>where $s = t - \Delta t$. We let ${\gamma_t}$ and ${\sigma_t^2}$ be such that $q(z_t \mid z_0) = \mathcal{N}(z_t; \gamma_t z_0, \sigma_t^2 I)$, and define the Signal-to-Noise Ratio (SNR) as $\mathrm{SNR}(t) = \gamma_t^2 / \sigma_t^2$. This is a strictly monotonic decreasing function of $t$.</p> <p>The key insight relies on how the posterior $q(z_s \mid z_t, z_0)$ and the transition $p_{\theta}(z_s \mid z_t)$ are parameterized. As $\Delta t \to 0$, both distributions are Gaussians with matched variances $\sigma^2$. Therefore, the KL divergence between these two distributions has a simple closed form. <d-cite key="kingma2021variational"></d-cite> deduce the following relation:</p> \[\begin{equation} D_{\mathrm{KL}}(q(z_{s} \mid z_t, z_0) \mid p_{\theta}(z_{s} \mid z_t)) = \frac{1}{2} (\mathrm{SNR}(s) - \mathrm{SNR}(t)) \mid z_0 - \hat{z}_{\theta}(z_t, t) \|_2^2. \end{equation}\] <p>We sum these terms over all timesteps $t$ and take the limit as $T \to \infty$ (implying $\Delta t \to 0$). The finite difference term, $\mathrm{SNR}(s) - \mathrm{SNR}(t)$, converges to $-\mathrm{SNR}’(t) \mathrm{d} t$, and the discrete sum converges to a Riemann integral: \(\begin{equation} \label{eq:vdm_obj} \mathcal{L}_{\infty}(\theta; z_0) = \frac{1}{2} \, \mathbb{E}_{t \sim \mathcal{U}(0,1)} \left[ -\mathrm{SNR}'(t) \mid z_0 - \hat{z}_{\theta}(z_t, t) \|_2^2 \right] + C, \end{equation}\)</p> <p>where $C$ is a constant irrelevant to the optimization. This formulation reveals that the continuous-time ELBO is invariant to the noise schedule, depending only on the SNR values at the endpoints. Indeed, we can perform the change of variables $v = \mathrm{SNR}(t)$. We have $\mathrm{d}v = \mathrm{SNR}’(t) \mathrm{d}t$, and we can swap the integration bounds from $[0, 1]$ to $[\mathrm{SNR}(1), \mathrm{SNR}(0)]$. We deduce:</p> \[\mathcal{L}_{\infty}(\theta; z_0) = \frac{1}{2} \int_{\mathrm{SNR}(1)}^{\mathrm{SNR}(0)} \| z_0 - \hat{z}(z_v) \|^2 \mathrm{d}v+C.\] <figure id="fig:fig_vlb_invariance" class="caption"> <img src="/2026-iclr-blogpost-earth4d/assets/img/2026-04-27-generalization-in-diffusion-as-infinite-hvae/vlb_invariance_multi_dataset.png" alt="Variational lower bound (VLB)" style="max-width: 100%; height: auto; image-rendering: auto;"> <div class="caption"> <strong>Figure 3:</strong> Variational lower bound (VLB) trajectories for three datasets (CIFAR-10, CelebA, ImageNet-32) under different noise schedules: Linear, Cosine, and Quadratic. Although the VLB progression differs across datasets and schedules, all curves converge to a similar final value, demonstrating the invariance of the ultimate sample variance across both datasets and noise schedules. </div> </figure> <p>This property reinforces the interpretation of diffusion models as continuous-time HVAEs. In discrete HVAEs, the ELBO value is determined by the total information content rather than the granularity of the layers; the KL regularization terms simply redistribute along the hierarchy without altering their integral. Diffusion models exhibit an identical mechanism: changing the noise schedule (e.g., to linear, cosine, or sigmoid) merely reparameterizes the temporal variable $t$ without modifying the endpoints $x_0$ and $x_T$. Consequently, the VLB is a function of the <em>geometry</em> of the latent trajectory, not its specific temporal speed. We empirically validate this invariance in <a href="#fig:fig_vlb_invariance">Figure 3</a>. The left panel reports the VLB calculated on <em>CIFAR-10</em> across varying noise schedules, while the right panel tracks the cumulative KL divergence. While different schedules alter the density of the KL divergence over time, the total integral (VLB) remains constant, confirming the continuous-time HVAE hypothesis.</p> <p><strong>Alternative view with the Girsanov Theorem.</strong></p> <p>Building on <d-cite key="huang2021variational"></d-cite>, we extend the approach of <d-cite key="kingma2021variational"></d-cite> to derive a similar result using the Girsanov theorem. While <d-cite key="kingma2021variational"></d-cite> arrive at the continuous-time objective by taking the limit of the reconstruction error as $T$ goes to infinity, <d-cite key="huang2021variational"></d-cite> propose a control-theoretic perspective. In their derivation, the KL divergence manifests as a quadratic <em>control cost</em> corresponding to the energy required to steer the random Brownian paths toward the data distribution. Although these views seem distinct in that they operate on different domains (<d-cite key="kingma2021variational"></d-cite> minimize the error in the signal domain, while <d-cite key="huang2021variational"></d-cite> work in the drift domain), they are actually equivalent. The energy required to convert the Brownian path into the data distribution is proportional to the squared score matching error, which is a weighted version of the reconstruction error. <a href="#fig:trajectories_level_noise">Figure 4</a> shows the reverse diffusion trajectories of weather image generation. The slider allows sweeping through the time index $t$, revealing how samples progressively denoise. Different random seeds can be selected to illustrate variability across generative trajectories, providing an interactive view of the model’s dynamics.</p> <p>This finally bridges the gap: training a diffusion model is the same as training an infinitely deep HVAE by maximizing a continuous-time ELBO.</p> <figure id="fig:trajectories_level_noise" class="caption"> <div class="l-page"> <iframe src="/2026-iclr-blogpost-earth4d/assets/html/2026-04-27-generalization-in-diffusion-as-infinite-hvae/trajectories_level_noise_interactive_weather.html" frameborder="0" scrolling="no" height="450px" width="900px"></iframe> </div> <div class="caption"> <strong>Figure 4:</strong> Drag the slider to sweep the time index $t$ and inspect how the image generation of weather evolve across the reverse process of diffusion. </div> </figure> <p><br></p> <h3 id="44-generalization-capabilities">4.4 Generalization Capabilities</h3> <p>In a recent work, <d-cite key="chen2025generalization"></d-cite> provide key insights into the generalization properties of VAEs and DPMs. While we have established that DPMs can be viewed as HVAEs with $T\to+\infty$, <d-cite key="chen2025generalization"></d-cite> argue that increasing the depth of the model is not necessarily ideal for generalization.</p> <p>They identify a trade-off involving the diffusion time $T$:</p> <ul> <li> <em>Small $T$:</em> the model behaves like a shallow VAE where the encoder dominates, potentially leading to overfitting (memorization).</li> <li> <em>Large $T$:</em> the encoder’s influence vanishes (as the signal becomes pure noise), but the generator’s burden increases.</li> </ul> <p>This suggests that while the <em>architectural</em> equivalence exists in the limit, the <em>optimal operating point</em> for a generative model lies at a finite depth, a sweet spot where the model balances structural guidance (encoder) with texture synthesis (generator).</p> <table> <thead> <tr style="background-color: rgb(118, 20, 255); color: white; text-align: center;"> <th>Time ($T$)</th> <th>Encoder Error</th> <th>Generator Error</th> <th>Total Bound</th> </tr> </thead> <tbody> <tr> <td style="text-align:center;">0.20</td> <td style="text-align:center;">0.532 ± 0.017</td> <td style="text-align:center;">0.158 ± 0.008</td> <td style="text-align:center;">0.690 ± 0.018</td> </tr> <tr> <td style="text-align:center;">0.50</td> <td style="text-align:center;">0.279 ± 0.011</td> <td style="text-align:center;">0.250 ± 0.014</td> <td style="text-align:center;">0.528 ± 0.016</td> </tr> <tr> <td style="text-align:center;"><strong>0.75</strong></td> <td style="text-align:center;"><strong style="color: rgb(118, 20, 255);">0.172 ± 0.008</strong></td> <td style="text-align:center;"><strong style="color: rgb(118, 20, 255);">0.326 ± 0.016</strong></td> <td style="text-align:center;"><strong style="color: rgb(118, 20, 255);">0.498 ± 0.018</strong></td> </tr> <tr> <td style="text-align:center;">1.00</td> <td style="text-align:center;">0.115 ± 0.010</td> <td style="text-align:center;">0.401 ± 0.018</td> <td style="text-align:center;">0.516 ± 0.018</td> </tr> <tr> <td style="text-align:center;">1.50</td> <td style="text-align:center;">0.071 ± 0.006</td> <td style="text-align:center;">0.544 ± 0.020</td> <td style="text-align:center;">0.615 ± 0.019</td> </tr> <tr> <td style="text-align:center;">2.00</td> <td style="text-align:center;">0.057 ± 0.005</td> <td style="text-align:center;">0.698 ± 0.040</td> <td style="text-align:center;">0.756 ± 0.041</td> </tr> </tbody> </table> <p><strong>Table 1:</strong> Quantitative analysis of the Generalization Trade-off w.r.t Diffusion Time $T$. The Total Bound reaches its minimum (the “Sweet Spot”) at $T=0.75$. At low $T$, the Encoder is unstable, while at high $T$, the Generator becomes the primary source of variance. <br></p> <table> <thead> <tr style="background-color: rgb(118, 20, 255); color: white; text-align: center;"> <th>Model</th> <th>Type</th> <th>CIFAR-10</th> <th>CelebA</th> <th>ImageNet 32×32</th> </tr> </thead> <tbody> <tr> <td>NVAE, L=8</td> <td>VAE</td> <td>3.20</td> <td>4.05</td> <td>4.50</td> </tr> <tr> <td>NVAE, L=18</td> <td>VAE</td> <td>3.05</td> <td>3.95</td> <td>4.30</td> </tr> <tr> <td>NVAE, L=32</td> <td>VAE</td> <td>2.97</td> <td>3.92</td> <td>4.20</td> </tr> <tr> <td>NVAE, L=64</td> <td>VAE</td> <td>2.93</td> <td>3.90</td> <td>4.10</td> </tr> <tr> <td>NVAE, L=128</td> <td>VAE</td> <td><strong style="color: rgb(118, 20, 255);">2.91</strong></td> <td>3.88</td> <td>4.05</td> </tr> <tr> <td>DDPM [Ho et al., 2020]</td> <td>Diffusion</td> <td>3.10</td> <td>3.69</td> <td>3.95</td> </tr> <tr> <td>EBM-DRL [Gao et al., 2020]</td> <td>Diffusion</td> <td>3.05</td> <td>3.18</td> <td>3.90</td> </tr> <tr> <td>Score SDE [Song et al., 2021b]</td> <td>Diffusion</td> <td>2.99</td> <td>3.25</td> <td>3.85</td> </tr> <tr> <td>Improved DDPM [Nichol and Dhariwal, 2021]</td> <td>Diffusion</td> <td>2.94</td> <td>3.54</td> <td>3.80</td> </tr> <tr> <td>LSGM [Vahdat et al., 2021]</td> <td>Diffusion</td> <td>2.87</td> <td>3.30</td> <td>3.75</td> </tr> <tr> <td>ScoreFlow [Song et al., 2021a] (variational bound)</td> <td>Diffusion</td> <td>2.90</td> <td>3.50</td> <td>3.86</td> </tr> <tr> <td>ScoreFlow [Song et al., 2021a] (continuous norm. flow)</td> <td>Diffusion</td> <td><strong style="color: rgb(118, 20, 255);">2.83</strong></td> <td><strong style="color: rgb(118, 20, 255);">2.80</strong></td> <td><strong style="color: rgb(118, 20, 255);">3.76</strong></td> </tr> </tbody> </table> <p><strong>Table 2:</strong> Benchmarking NVAE variants versus Diffusion Models. Bits per dimension (BPD) on CIFAR-10 and ImageNet test sets. NVAE variants differ by the number of hierarchical layers $L$.</p> <p><br></p> <h2 id="5-concluding-remarks">5. Concluding Remarks</h2> <p>In this post, we have bridged the gap between two dominant generative paradigms, demonstrating that Diffusion Probabilistic Models are not distinct from Variational Auto-Encoders, but are rigorously equivalent to Hierarchical VAEs in the limit of infinite depth under a particular parameterization. This shift in perspective from discrete layers to continuous time resolves the critical bottlenecks that have historically limited deep VAEs:</p> <ul> <li> <p><strong>Solving Posterior Collapse:</strong> By fixing the encoder to a noise-injection process (the forward diffusion), DPMs bypass the optimization instability where the encoder ignores the latent code. The <em>inference</em> is no longer learned but prescribed by physics.</p> </li> <li> <p><strong>Generalization “Sweet Spot”:</strong> Diffusion can be viewed as an infinite-depth HVAE, which helps explain the gap between Diffusion and standard VAEs observed in our results. While the theory holds in the infinite limit ($T \to \infty$), recent insights suggest that optimal generalization often emerges at a finite depth. The balance between the encoder’s structural constraints and the generator’s texture synthesis yields an optimal operating point for sample quality, one that diffusion models naturally pass through.</p> </li> </ul> <p>Ultimately, viewing diffusion as an infinite HVAE provides more than just theoretical satisfaction. It offers a sober look at the model’s capabilities, suggesting that the secret to their success lies not in magic, but in the rigorous scaling of hierarchical Bayesian inference.</p> <aside class="l-body box-note" markdowk="1"> <strong>Key Takeaway:</strong> Diffusion models work because they are the first scalable implementation of infinite-depth HVAEs. They trade the complex, learnable encoder of standard VAEs for a stable, fixed forward process that forces the generator to cover the entire data manifold without collapsing. </aside> <p><br></p> <p><strong>Limitations</strong> While the HVAE perspective illuminates the structure of diffusion models, it remains an idealized view: real models operate at finite depth, introducing discretization gaps that depart from the continuous-time theory. The fixed forward process, although stabilizing, also limits encoder flexibility and may fail to capture richer posterior structures. Moreover, diffusion models still suffer from high computational cost due to their iterative sampling and rely on hand-designed noise schedules that are not guaranteed to be optimal for every dataset.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026-iclr-blogpost-earth4d/assets/bibliography/2026-04-27-generalization-in-diffusion-as-infinite-hvae.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026-iclr-blogpost-earth4d/blog/2026/ppo-batch-size/">The Trade-off Between Parallel Environments and Steps in PPO</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026-iclr-blogpost-earth4d/blog/2026/beyond-attention-as-graph/">Beyond Attention as a Graph</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026-iclr-blogpost-earth4d/blog/2026/attention-sinks-graph-perspective/">Attention Sinks from the Graph Perspective</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026-iclr-blogpost-earth4d/blog/2026/agent-evaluation/">A Hitchhiker's Guide to Agent Evaluation</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026-iclr-blogpost-earth4d/blog/2026/zero-rewards/">What Can You Do When You Have Zero Rewards During RL?</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026-iclr-blogpost-earth4d/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026-iclr-blogpost-earth4d/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026-iclr-blogpost-earth4d/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026-iclr-blogpost-earth4d/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026-iclr-blogpost-earth4d/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026-iclr-blogpost-earth4d/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026-iclr-blogpost-earth4d/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026-iclr-blogpost-earth4d/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/search-data.js"></script> <script src="/2026-iclr-blogpost-earth4d/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>