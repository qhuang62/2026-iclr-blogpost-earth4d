@article{Antunes2024,
  title   = {Crystal structure generation with autoregressive large language modeling},
  author  = {Antunes, Luis M. and Butler, Keith T. and Grau-Crespo,  Ricardo},
  journal = {Nature Communications},
  year    = {2024},
  url     = {http://dx.doi.org/10.1038/s41467-024-54639-7}
}

@inproceedings{10.1609/aaai.v39i24.34804,
  title  = {BindGPT: a scalable framework for 3D molecular design via language modeling and reinforcement learning},
  author = {Zholus, Artem and Kuznetsov, Maksim and Schutski, Roman and Shayakhmetov, Rim and Polykovskiy, Daniil and Chandar, Sarath and Zhavoronkov, Alex},
  year   = {2025},
  url    = {https://doi.org/10.1609/aaai.v39i24.34804}
}

@misc{sun2024autoregressivemodelbeatsdiffusion,
  title  = {Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation},
  author = {Peize Sun and Yi Jiang and Shoufa Chen and Shilong Zhang and Bingyue Peng and Ping Luo and Zehuan Yuan},
  year   = {2024},
  url    = {https://arxiv.org/abs/2406.06525}
}

@inproceedings{wang2024diverse,
  title  = {Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules},
  author = {Binxu Wang and Jiaqi Shang and Haim Sompolinsky},
  year   = {2024},
  url    = {https://openreview.net/forum?id=FNFxd2mV2U}
}

@inproceedings{chen2024diffusion,
  title  = {Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion},
  author = {Boyuan Chen and Diego Mart{\'\i} Mons{\'o} and Yilun Du and Max Simchowitz and Russ Tedrake and Vincent Sitzmann},
  year   = {2024},
  url    = {https://openreview.net/forum?id=yDo1ynArjj}
}

@misc{chen2021evaluatinglargelanguagemodels,
  title  = {Evaluating Large Language Models Trained on Code},
  author = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  year   = {2021},
  url    = {https://arxiv.org/abs/2107.03374}
}

@misc{openai2024gpt4technicalreport,
  title  = {GPT-4 Technical Report},
  author = {OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
  year   = {2024},
  url    = {https://arxiv.org/abs/2303.08774}
}

@inproceedings{10.1609/aaai.v33i01.33013159,
  title  = {Character-level language modeling with deeper self-attention},
  author = {Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo, Mandy and Jones, Llion},
  year   = {2019},
  url    = {https://doi.org/10.1609/aaai.v33i01.33013159}
}

@inproceedings{sennrich-etal-2016-neural,
  title   = {Neural Machine Translation of Rare Words with Subword Units},
  author  = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  year    = {2016},
  url     = {https://aclanthology.org/P16-1162/},
  journal = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}
}

@inproceedings{devlin-etal-2019-bert,
  title   = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year    = {2019},
  url     = {https://aclanthology.org/N19-1423/},
  journal = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics}
}

@inproceedings{neitemeier2025hierarchical,
  title  = {Hierarchical Autoregressive Transformers: Combining Byte- and Word-Level Processing for Robust, Adaptable Language Models},
  author = {Pit Neitemeier and Bj{\"o}rn Deiseroth and Constantin Eichenberg and Lukas Balles},
  year   = {2025},
  url    = {https://openreview.net/forum?id=tU074jg2vS}
}

@inproceedings{pagnoni-etal-2025-byte,
  title  = {Byte Latent Transformer: Patches Scale Better Than Tokens},
  author = {Pagnoni, Artidoro and Pasunuru, Ramakanth and Rodriguez, Pedro and Nguyen, John and Muller, Benjamin and Li, Margaret and Zhou, Chunting and Yu, Lili and Weston, Jason E and Zettlemoyer, Luke and Ghosh, Gargi and Lewis, Mike and Holtzman, Ari and Iyer, Srini},
  year   = {2025},
  url    = {https://aclanthology.org/2025.acl-long.453/}
}

@misc{hwang2025dynamicchunkingendtoendhierarchical,
  title  = {Dynamic Chunking for End-to-End Hierarchical Sequence Modeling},
  author = {Sukjun Hwang and Brandon Wang and Albert Gu},
  year   = {2025},
  url    = {https://arxiv.org/abs/2507.07955}
}

@inproceedings{Hafner2020Dream,
  title  = {Dream to Control: Learning Behaviors by Latent Imagination},
  author = {Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
  year   = {2020},
  url    = {https://openreview.net/forum?id=S1lOTC4tDS}
}

@inproceedings{Xu2020A,
  title  = {A Theory of Usable Information under Computational Constraints},
  author = {Yilun Xu and Shengjia Zhao and Jiaming Song and Russell Stewart and Stefano Ermon},
  year   = {2020},
  url    = {https://openreview.net/forum?id=r1eBeyHFDH}
}

@misc{dieleman2025latents,
  title  = {Generative modelling in latent space},
  author = {Dieleman, Sander},
  year   = {2025},
  url    = {https://sander.ai/2025/04/15/latents.html}
}

@misc{tschannen2018recentadvancesautoencoderbasedrepresentation,
  title  = {Recent Advances in Autoencoder-Based Representation Learning},
  author = {Michael Tschannen and Olivier Bachem and Mario Lucic},
  year   = {2018},
  url    = {https://arxiv.org/abs/1812.05069}
}

@misc{rajaraman2025theorytokenizationllms,
  title  = {Toward a Theory of Tokenization in LLMs},
  author = {Nived Rajaraman and Jiantao Jiao and Kannan Ramchandran},
  year   = {2025},
  url    = {https://arxiv.org/abs/2404.08335}
}

@inproceedings{kim2025train,
  title  = {Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions},
  author = {Jaeyeon Kim and Kulin Shah and Vasilis Kontonis and Sham M. Kakade and Sitan Chen},
  year   = {2025},
  url    = {https://openreview.net/forum?id=DjJmre5IkP}
}

@misc{singh2024tokenizationcountsimpacttokenization,
  title  = {Tokenization counts: the impact of tokenization on arithmetic in frontier LLMs},
  author = {Aaditya K. Singh and DJ Strouse},
  year   = {2024},
  url    = {https://arxiv.org/abs/2402.14903}
}

@misc{lee2024digitstodecisions,
  title  = {From Digits to Decisions: How Tokenization Impacts Arithmetic in LLMs},
  author = {Garreth Lee, Guilherme Penedo, Leandro von Werra and Thomas Wolf},
  url    = {https://huggingface.co/spaces/huggingface/number-tokenization-blog}
}

@inproceedings{hoogeboom2022autoregressive,
  title  = {Autoregressive Diffusion Models},
  author = {Emiel Hoogeboom and Alexey A. Gritsenko and Jasmijn Bastings and Ben Poole and Rianne van den Berg and Tim Salimans},
  year   = {2022},
  url    = {https://openreview.net/forum?id=Lm8T39vLDTE}
}

@inproceedings{arriola2025block,
  title  = {Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models},
  author = {Marianne Arriola and Subham Sekhar Sahoo and Aaron Gokaslan and Zhihan Yang and Zhixuan Qi and Jiaqi Han and Justin T Chiu and Volodymyr Kuleshov},
  year   = {2025},
  url    = {https://openreview.net/forum?id=tyEyYT267x}
}

@inproceedings{10.5555/3045390.3045575,
  title  = {Pixel recurrent neural networks},
  author = {Van Den Oord, A\"{a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  year   = {2016},
  url    = {}
}

@misc{theis2016noteevaluationgenerativemodels,
  title  = {A note on the evaluation of generative models},
  author = {Lucas Theis and Aäron van den Oord and Matthias Bethge},
  year   = {2016},
  url    = {https://arxiv.org/abs/1511.01844}
}

@inproceedings{dosovitskiy2021an,
  title  = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  year   = {2021},
  url    = {https://openreview.net/forum?id=YicbFdNTTy}
}

@misc{esser2020taming,
  title  = {Taming Transformers for High-Resolution Image Synthesis},
  author = {Patrick Esser and Robin Rombach and Björn Ommer},
  year   = {2020}
}

@inproceedings{vandenOord2017,
  title   = {Neural Discrete Representation Learning},
  author  = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu, koray},
  journal = {Advances in Neural Information Processing Systems},
  year    = {2017},
  url     = {https://proceedings.neurips.cc/paper_files/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf}
}

@article{lester2024training,
  title   = {Training LLMs over Neurally Compressed Text},
  author  = {Brian Lester and Jaehoon Lee and Alexander A Alemi and Jeffrey Pennington and Adam Roberts and Jascha Sohl-Dickstein and Noah Constant},
  journal = {Transactions on Machine Learning Research},
  year    = {2024},
  url     = {https://openreview.net/forum?id=pRvhMSV48t}
}

@inproceedings{wang2025learningorder,
  title  = {Learning-Order Autoregressive Models with Application to Molecular Graph Generation},
  author = {Zhe Wang and Jiaxin Shi and Nicolas Heess and Arthur Gretton and Michalis Titsias},
  year   = {2025},
  url    = {https://openreview.net/forum?id=EY6pXIDi3G}
}

@inproceedings{10.1007/978-3-031-70368-3_9,
  title  = {σ-GPTs: A New Approach to Autoregressive Models},
  author = {Pannatier, Arnaud and Courdier, Evann and Fleuret, Fran\c{c}ois},
  year   = {2024},
  url    = {https://doi.org/10.1007/978-3-031-70368-3_9}
}

@misc{pramanik2025distillingsemanticallyawareorders,
  title  = {Distilling semantically aware orders for autoregressive image generation},
  author = {Rishav Pramanik and Antoine Poupon and Juan A. Rodriguez and Masih Aminbeidokhti and David Vazquez and Christopher Pal and Zhaozheng Yin and Marco Pedersoli},
  year   = {2025},
  url    = {https://arxiv.org/abs/2504.17069}
}

@misc{kutscher2025reorderingpatchesimprovesvision,
  title  = {REOrdering Patches Improves Vision Models},
  author = {Declan Kutscher and David M. Chan and Yutong Bai and Trevor Darrell and Ritwik Gupta},
  year   = {2025},
  url    = {https://arxiv.org/abs/2505.23751}
}

@inproceedings{tian2024visual,
  title  = {Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction},
  author = {Keyu Tian and Yi Jiang and Zehuan Yuan and BINGYUE PENG and Liwei Wang},
  year   = {2024},
  url    = {https://openreview.net/forum?id=gojL67CfS8}
}

@inproceedings{bachmann2025flextok,
  title  = {FlexTok: Resampling Images into 1D Token Sequences of Flexible Length},
  author = {Roman Bachmann and Jesse Allardice and David Mizrahi and Enrico Fini and O{\u{g}}uzhan Fatih Kar and Elmira Amirloo and Alaaeldin El-Nouby and Amir Zamir and Afshin Dehghan},
  year   = {2025},
  url    = {https://openreview.net/forum?id=DgdOkUUBzf}
}

@inproceedings{cai2025matryoshka,
  title  = {Matryoshka Multimodal Models},
  author = {Mu Cai and Jianwei Yang and Jianfeng Gao and Yong Jae Lee},
  year   = {2025},
  url    = {https://openreview.net/forum?id=Uhj5OxAz7I}
}

@misc{miwa2025onedpieceimagetokenizermeets,
  title={One-D-Piece: Image Tokenizer Meets Quality-Controllable Compression}, 
  author={Keita Miwa and Kento Sasaki and Hidehisa Arai and Tsubasa Takahashi and Yu Yamaguchi},
  year={2025},
  url={https://arxiv.org/abs/2501.10064}, 
}

@inproceedings{ramanujan2025when,
  title  = {When Worse is Better: Navigating the Compression Generation Trade-off In Visual Tokenization},
  author = {Vivek Ramanujan and Kushal Tirumala and Armen Aghajanyan and Luke Zettlemoyer and Ali Farhadi},
  year   = {2025},
  url    = {https://openreview.net/forum?id=o8hWyJIgAV}
}

@misc{wu2025sequencemodelingalignmenttokenizer,
  title  = {Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model},
  author = {Pingyu Wu and Kai Zhu and Yu Liu and Longxiang Tang and Jian Yang and Yansong Peng and Wei Zhai and Yang Cao and Zheng-Jun Zha},
  year   = {2025},
  url    = {https://arxiv.org/abs/2506.05289}
}

@inproceedings{wang2025larp,
  title  = {{LARP}: Tokenizing Videos with a Learned Autoregressive Generative Prior},
  author = {Hanyu Wang and Saksham Suri and Yixuan Ren and Hao Chen and Abhinav Shrivastava},
  year   = {2025},
  url    = {https://openreview.net/forum?id=Wr3UuEx72f}
}

@inproceedings{tschannen2025jetformer,
  title  = {JetFormer: An autoregressive generative model of raw images and text},
  author = {Michael Tschannen and Andr{\'e} Susano Pinto and Alexander Kolesnikov},
  year   = {2025},
  url    = {https://openreview.net/forum?id=sgAp2qG86e}
}

@misc{sun2025enhancinglatentcomputationtransformers,
  title  = {Enhancing Latent Computation in Transformers with Latent Tokens},
  author = {Yuchang Sun and Yanxi Chen and Yaliang Li and Bolin Ding},
  year   = {2025},
  url    = {https://arxiv.org/abs/2505.12629}
}

@inproceedings{cao-rimell-2021-evaluate,
  title   = {You should evaluate your language model on marginal likelihood over tokenisations},
  author  = {Cao, Kris and Rimell, Laura},
  year    = {2021},
  url     = {https://aclanthology.org/2021.emnlp-main.161/},
  journal = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing}
}

@misc{falck2025fourier,
  title  = {A Fourier Space Perspective on Diffusion Models},
  author = {Falck, Fabian and Pandeva, Teodora and Zahirnia, Kiarash and Lawrence, Rachel and Turner, Richard E. and Meeds, Edward and Zazo, Javier and Karmalkar, Sushrut},
  year   = {2025},
  url    = {https://arxiv.org/abs/2505.11278}
}

@inproceedings{Ho2020,
  title   = {Denoising Diffusion Probabilistic Models},
  author  = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal = {Advances in Neural Information Processing Systems},
  year    = {2020},
  url     = {https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf}
}

@inproceedings{austin2021,
  title   = {Structured Denoising Diffusion Models in Discrete State-Spaces},
  author  = {Austin, Jacob and Johnson, Daniel D. and Ho, Jonathan and Tarlow, Daniel and van den Berg, Rianne},
  journal = {Advances in Neural Information Processing Systems},
  year    = {2021},
  url     = {https://proceedings.neurips.cc/paper_files/paper/2021/file/958c530554f78bcd8e97125b70e6973d-Paper.pdf}
}

@inproceedings{lou2024discrete,
  title  = {Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution},
  author = {Aaron Lou and Chenlin Meng and Stefano Ermon},
  year   = {2024},
  url    = {https://openreview.net/forum?id=CNicRIVIPA}
}

@inproceedings{zheng2025masked,
  title={Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling},
  author={Kaiwen Zheng and Yongxin Chen and Hanzi Mao and Ming-Yu Liu and Jun Zhu and Qinsheng Zhang},
  year={2025},
  url={https://openreview.net/forum?id=CTC7CmirNr}
}

@inproceedings{haviv-etal-2022-transformer,
    title = "Transformer Language Models without Positional Encodings Still Learn Positional Information",
    author = "Haviv, Adi  and
      Ram, Ori  and
      Press, Ofir  and
      Izsak, Peter  and
      Levy, Omer",
    year = "2022",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.99/",
}